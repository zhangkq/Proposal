\section{Introduction}\label{ch:overview}
\subsection{Background}
Data centres provide the IT infrastructure that powers many of today's computing environments – from the Internet to the mobile cloud – and are currently a \$50 billion market with an exponential growth rate~\cite{bigdatacentre}. Energy consumption is the fundamental issue for data centres~\cite{EPAreport,Energygov}. Electricity costs typically make up 70\% of operating expense of high end servers~\cite{}. In the UK data centres account for 3\% of total domestic electricity use, or equivalent to one nuclear power station~\cite{globalactionplan}. The total carbon footprint of the world's data centres is approximately the same as the carbon emissions of the entire Czech Republic and will triple by 2020~\cite{GeSI}.  Given the increasing demand of computing power of data centres and the rising cost of energy, there is a critical need to optimise data centre applications for both raw performance and energy consumption.

Hardware manufacturers have responded to this issue by making enormous strides in managing power demands of processors~\cite{}. Sophisticated power management features, such as dynamic voltage and frequency scaling and heterogeneous processing units, are now placed across system components, hoping that software techniques will be found to make use of them. Software developers, however, are struggling to cope with this dramatic increase in complexity, the existing tools and languages are simply inadequate to the task. As a result, today’s data centres suffer embarrassing energy inefficiencies: it is not unusual for less than 20\% of the power is used to perform useful work for data centres~\cite{}. This situation has to change.

\subsection{Research Challenges}
However, improving energy efficiency for data centres is challenging. Firstly, the hardware resources are often conservatively provisioned (e.g. machines operate on the peak power mode as unnecessarily)  for rare utilisation peaks because of being unable to accurately predict the load peaks~\cite{energy-aware,towardsenergyeff}. This leads to energy waste in underutilised systems. Secondly, server applications are currently hard-coded and optimised for a fully utilised system, but energy efficiency generally degrades outside that range~\cite{towardsenergyeff,autodatacentre}. As such, techniques that can dynamically tailor programs according to workload and resource changes are essential for energy efficiency~\cite{towardsenergyeff}. Unfortunately, servers are a truly multi-tasking environment (where thousands of tasks running at the same time, competing for shared resources), often with the support of virtualisation technology~\cite{energy-effcloud}, creating enormous difficulties for software power optimisation. This situation becomes more difficult as more and more heterogeneous hardware are used now days~\cite{aview}. What is needed is a technique that \textbf{evolves and adapts to the changing workload and resource and delivers scalable energy-efficient performance}.

\subsection{Proposed Research}
This research will use predictive modelling techniques to model and predict data centres workloads. It will design a new Linux scheduler to make use of the accurate workload prediction to quickly react to the change of workload demands and precisely allocate server resources.  Furthermore, to harness the potential of dynamic resource scheduling, applications must be tailored to fit the drastically changing computing environment, as a poorly optimised program can overshadow any energy benefits that would have been obtained. To this end, this research will investigate program tuning techniques that enable us to tailor applications on-the-fly (e.g. dynamically replacing the algorithm or data structure as the program runs). On top of these, we would like the system software to catch up with the evolving hardware, applications and workloads and to deliver ``future scalable" performance. To achieve this, I will explore an innovative \textbf{machine-learning-based} approach that self-adapts to future hardware and applications, and improves its performance over time.

\subsection{Expected Outcome and Impact}
This project will create a novel predictive modelling based task and resource scheduler in the Linux operating system. It will also develop energy-aware compilation heuristics and optimisation algorithms in the Jike JVM~\cite{}, targeting heterogeneous many-core systems.
When this project  is successful, the tool-chain it creates will show how to harness the potential of heterogeneous many-cores (for example, a CPU-GPU based system). The techniques will be demonstrated on real world applications in the domains of data-intensive applications such as Hadoop based  database system. We will show that our automatic optimisations are able to increase performance and energy efficiency for those applications by \textbf{50\%} compared to unoptimised code, and are not more than 5\% away from hand optimisation. We will prove the \textbf{portability} of our system by showing that our applications remain optimised for different architectures, \textbf{without the developer needing to alter a single line of code}.

\subsection{Novelty}
Machine learning has recently been proved to be effective at learning how to optimise programs in a static environment~\cite{wangf,wangs}. The way is now open, for the first time, for those techniques t\textbf{o be tried in a large-scale, ever-changing server environment; continuously improve over time}. This project cuts across different layers of the software stack, bringing together workload modelling, runtime program optimisation and resource scheduling to address a critical problem in a way that has never been attempted. There are great challenges ahead and enormous scope for interesting, high impact research to be carried out in this new area.

%Need of Energy-efficiency:
%Data centres are the facilities for holding computers, communication equipments and huge data storage. As the infrastructure of the modern electronic world, there is a \$50 billion market with an exponential growth rate\cite{bigdatacentre}. However, the energy consumption has become the fundamental issue for data centres\cite{EPAreport}\cite{Energygov}. For instance, the UK spends 3\% of total domestic electricity usage on data centres in, which equals to one nuclear power plant\cite{globalactionplan}. The carbon emission of the world’s data centres is approximate to the carbon footprint of the entire Czech Republic and will be tripled by 2020\cite{GeSI}. With the increasing demand of data centres, the energy efficiency problems draw improving attractions among the world.
%%Need for optimisation software
%\\
%\linebreak
%Hardware engineers are striving to resolve the energy issue through power management techniques in processors\cite{chanandopp}. They developed various power management features, like dynamic voltage, frequency scaling and heterogeneous processors, which have been applied in system components. Unfortunately, there are still no clear clues for software to realise the hardware potential\cite{lookbackandfor}\cite{towardsenergyeff}. Therefore, the data centres are often spend less than 20\% of the entire power consumption to perform the useful work, i.e. almost 80\% of the data centres power usage is wasted\cite{thecaseforepc}.
%However, energy efficiency improvement for data centres is challenging. In detail, the hardware resources are often conservatively provisioned for rare utilisation peaks because of inability to predict the load peaks accurately\cite{energy-aware}\cite{towardsenergyeff}. Since machines operate on the peak power mode when it is unnecessary, this leads to energy waste in underutilised systems. On the other hand, server applications are currently hard-coded and optimised for a fully utilised system, but energy efficiency generally degrades outside that range\cite{towardsenergyeff}\cite{autodatacentre}. Thus, techniques that can tailor programs according to workload and resource changes are essential for energy efficiency\cite{towardsenergyeff}. Additionally, servers are truly multi-tasking environment, where thousands of tasks running at the same time, competing for shared resources, often with the support of virtualisation technology\cite{energy-effcloud}. This certainly creates huge difficulties for software power optimisation. The situation becomes more difficult as more and more heterogeneous hardware are used nowadays\cite{aview}. Towards energy efficiency data centres, a technique that evolves and adapts to the changing workload and resource and delivers scalable energy-efficient performance is needed.
%\\
%\linebreak
%%Advantages of using machine learning algorithms
%Machine learning provides the possibilities of implementing both of predictive and adaptive managing functions\cite{ma}. Machine learning has been proved for automatically static optimization of paralleling computation by Wang and O'Boyle\cite{wangf}\cite{wangs}. For a static analysis point of view, this intelligent program parallelism method achieves portability among different platforms without professional knowledge\cite{wangs}. It is possible to extend machine learning concepts on workload prediction and runtime scheduling, while adapting to changing environment, e.g. work load, hardware setup, and platforms. With efficient tasks scheduling, the performance of data centres can be improved with less energy usage by reducing recourse over provision.
